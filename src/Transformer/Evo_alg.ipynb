{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e23ad4c-ecb4-4241-86cf-6fab4676ada9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jupyterlab in /opt/conda/lib/python3.11/site-packages (4.2.5)\n",
      "Collecting jupyterlab-optuna\n",
      "  Downloading jupyterlab_optuna-0.2.2-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting rdkit\n",
      "  Downloading rdkit-2024.9.6-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting pysmiles\n",
      "  Downloading pysmiles-2.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting prettytable\n",
      "  Downloading prettytable-3.15.1-py3-none-any.whl.metadata (33 kB)\n",
      "Collecting pybel\n",
      "  Downloading pybel-0.15.5-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting optuna\n",
      "  Downloading optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from jupyterlab) (2.0.4)\n",
      "Requirement already satisfied: httpx>=0.25.0 in /opt/conda/lib/python3.11/site-packages (from jupyterlab) (0.27.2)\n",
      "Requirement already satisfied: ipykernel>=6.5.0 in /opt/conda/lib/python3.11/site-packages (from jupyterlab) (6.29.5)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in /opt/conda/lib/python3.11/site-packages (from jupyterlab) (3.1.4)\n",
      "Requirement already satisfied: jupyter-core in /opt/conda/lib/python3.11/site-packages (from jupyterlab) (5.7.2)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from jupyterlab) (2.2.5)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /opt/conda/lib/python3.11/site-packages (from jupyterlab) (2.14.2)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in /opt/conda/lib/python3.11/site-packages (from jupyterlab) (2.27.3)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in /opt/conda/lib/python3.11/site-packages (from jupyterlab) (0.2.4)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from jupyterlab) (24.1)\n",
      "Requirement already satisfied: setuptools>=40.1.0 in /opt/conda/lib/python3.11/site-packages (from jupyterlab) (72.2.0)\n",
      "Requirement already satisfied: tornado>=6.2.0 in /opt/conda/lib/python3.11/site-packages (from jupyterlab) (6.4.1)\n",
      "Requirement already satisfied: traitlets in /opt/conda/lib/python3.11/site-packages (from jupyterlab) (5.14.3)\n",
      "Collecting bottle>=0.13.0 (from jupyterlab-optuna)\n",
      "  Downloading bottle-0.13.2-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.11/site-packages (from jupyterlab-optuna) (1.5.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from rdkit) (1.26.4)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.11/site-packages (from rdkit) (10.4.0)\n",
      "Collecting pbr (from pysmiles)\n",
      "  Downloading pbr-6.1.1-py2.py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from pysmiles) (3.3)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.11/site-packages (from prettytable) (0.2.13)\n",
      "Requirement already satisfied: sqlalchemy in /opt/conda/lib/python3.11/site-packages (from pybel) (2.0.32)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.11/site-packages (from pybel) (8.1.7)\n",
      "Collecting click-plugins (from pybel)\n",
      "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting bel-resources>=0.0.3 (from pybel)\n",
      "  Downloading bel_resources-0.0.3-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting more-itertools (from pybel)\n",
      "  Downloading more_itertools-10.6.0-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from pybel) (2.32.3)\n",
      "Collecting requests-file (from pybel)\n",
      "  Downloading requests_file-2.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: pyparsing in /opt/conda/lib/python3.11/site-packages (from pybel) (3.1.4)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from pybel) (4.66.5)\n",
      "Collecting humanize (from pybel)\n",
      "  Downloading humanize-4.12.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.11/site-packages (from pybel) (0.9.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from pybel) (2.1.4)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.11/site-packages (from pybel) (4.23.0)\n",
      "Collecting bioregistry (from pybel)\n",
      "  Downloading bioregistry-0.12.7-py3-none-any.whl.metadata (35 kB)\n",
      "Collecting ratelimit (from pybel)\n",
      "  Downloading ratelimit-2.2.1.tar.gz (5.3 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pystow>=0.1.2 (from pybel)\n",
      "  Downloading pystow-0.7.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting psycopg2-binary (from pybel)\n",
      "  Downloading psycopg2_binary-2.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.11/site-packages (from optuna) (1.13.2)\n",
      "Collecting colorlog (from optuna)\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.11/site-packages (from optuna) (6.0.2)\n",
      "Requirement already satisfied: Mako in /opt/conda/lib/python3.11/site-packages (from alembic>=1.5.0->optuna) (1.3.5)\n",
      "Requirement already satisfied: typing-extensions>=4 in /opt/conda/lib/python3.11/site-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
      "Collecting multisplitby (from bel-resources>=0.0.3->pybel)\n",
      "  Downloading multisplitby-0.0.1-py3-none-any.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.11/site-packages (from httpx>=0.25.0->jupyterlab) (4.4.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from httpx>=0.25.0->jupyterlab) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.11/site-packages (from httpx>=0.25.0->jupyterlab) (1.0.5)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.11/site-packages (from httpx>=0.25.0->jupyterlab) (3.8)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.11/site-packages (from httpx>=0.25.0->jupyterlab) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab) (0.14.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in /opt/conda/lib/python3.11/site-packages (from ipykernel>=6.5.0->jupyterlab) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /opt/conda/lib/python3.11/site-packages (from ipykernel>=6.5.0->jupyterlab) (1.8.5)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /opt/conda/lib/python3.11/site-packages (from ipykernel>=6.5.0->jupyterlab) (8.27.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /opt/conda/lib/python3.11/site-packages (from ipykernel>=6.5.0->jupyterlab) (8.6.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /opt/conda/lib/python3.11/site-packages (from ipykernel>=6.5.0->jupyterlab) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.11/site-packages (from ipykernel>=6.5.0->jupyterlab) (1.6.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from ipykernel>=6.5.0->jupyterlab) (6.0.0)\n",
      "Requirement already satisfied: pyzmq>=24 in /opt/conda/lib/python3.11/site-packages (from ipykernel>=6.5.0->jupyterlab) (26.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2>=3.0.3->jupyterlab) (2.1.5)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.11/site-packages (from jupyter-core->jupyterlab) (4.2.2)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in /opt/conda/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (23.1.0)\n",
      "Requirement already satisfied: jupyter-events>=0.9.0 in /opt/conda/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.10.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /opt/conda/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.5.3)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in /opt/conda/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (7.16.4)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in /opt/conda/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (5.10.4)\n",
      "Requirement already satisfied: overrides>=5.0 in /opt/conda/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (7.7.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in /opt/conda/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.20.0)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in /opt/conda/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in /opt/conda/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (1.8.0)\n",
      "Requirement already satisfied: babel>=2.10 in /opt/conda/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (2.14.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in /opt/conda/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (0.9.25)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.11/site-packages (from jsonschema->pybel) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.11/site-packages (from jsonschema->pybel) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.11/site-packages (from jsonschema->pybel) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from jsonschema->pybel) (0.20.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->pybel) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->pybel) (2.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.11/site-packages (from sqlalchemy->pybel) (3.0.3)\n",
      "Collecting more_click>=0.1.2 (from bioregistry->pybel)\n",
      "  Downloading more_click-0.1.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: pydantic>=2.0 in /opt/conda/lib/python3.11/site-packages (from pydantic[email]>=2.0->bioregistry->pybel) (2.8.2)\n",
      "Collecting curies>=0.7.0 (from bioregistry->pybel)\n",
      "  Downloading curies-0.10.10-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->pybel) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->pybel) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas->pybel) (2024.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn->jupyterlab-optuna) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn->jupyterlab-optuna) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn->jupyterlab-optuna) (3.5.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /opt/conda/lib/python3.11/site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (21.2.0)\n",
      "Collecting pytrie (from curies>=0.7.0->bioregistry->pybel)\n",
      "  Downloading PyTrie-0.4.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.19.1)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/conda/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (3.0.47)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (2.18.0)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.6.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (4.9.0)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /opt/conda/lib/python3.11/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (2.0.7)\n",
      "Requirement already satisfied: rfc3339-validator in /opt/conda/lib/python3.11/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /opt/conda/lib/python3.11/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (0.1.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.11/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (4.12.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /opt/conda/lib/python3.11/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (6.1.0)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.11/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.11/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /opt/conda/lib/python3.11/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (3.0.2)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /opt/conda/lib/python3.11/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.10.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.11/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in /opt/conda/lib/python3.11/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (1.3.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /opt/conda/lib/python3.11/site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab) (2.20.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from pydantic>=2.0->pydantic[email]>=2.0->bioregistry->pybel) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /opt/conda/lib/python3.11/site-packages (from pydantic>=2.0->pydantic[email]>=2.0->bioregistry->pybel) (2.20.1)\n",
      "Collecting email-validator>=2.0.0 (from pydantic[email]>=2.0->bioregistry->pybel)\n",
      "  Downloading email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->pybel) (1.16.0)\n",
      "Requirement already satisfied: ptyprocess in /opt/conda/lib/python3.11/site-packages (from terminado>=0.8.3->jupyter-server<3,>=2.4.0->jupyterlab) (0.7.0)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.11/site-packages (from bleach!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.5.1)\n",
      "Collecting dnspython>=2.0.0 (from email-validator>=2.0.0->pydantic[email]>=2.0->bioregistry->pybel)\n",
      "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.11/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.8.4)\n",
      "Requirement already satisfied: fqdn in /opt/conda/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /opt/conda/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /opt/conda/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (3.0.0)\n",
      "Requirement already satisfied: uri-template in /opt/conda/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in /opt/conda/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (24.8.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (1.17.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.11/site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (2.5)\n",
      "Requirement already satisfied: sortedcontainers in /opt/conda/lib/python3.11/site-packages (from pytrie->curies>=0.7.0->bioregistry->pybel) (2.4.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.2.3)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.11/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (2.22)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /opt/conda/lib/python3.11/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in /opt/conda/lib/python3.11/site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (2.9.0.20240821)\n",
      "Downloading jupyterlab_optuna-0.2.2-py3-none-any.whl (24.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading rdkit-2024.9.6-cp311-cp311-manylinux_2_28_x86_64.whl (34.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.3/34.3 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pysmiles-2.0.0-py2.py3-none-any.whl (37 kB)\n",
      "Downloading prettytable-3.15.1-py3-none-any.whl (33 kB)\n",
      "Downloading pybel-0.15.5-py3-none-any.whl (387 kB)\n",
      "Downloading optuna-4.2.1-py3-none-any.whl (383 kB)\n",
      "Downloading bel_resources-0.0.3-py3-none-any.whl (17 kB)\n",
      "Downloading bottle-0.13.2-py2.py3-none-any.whl (104 kB)\n",
      "Downloading pystow-0.7.0-py3-none-any.whl (38 kB)\n",
      "Downloading bioregistry-0.12.7-py3-none-any.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
      "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Downloading humanize-4.12.1-py3-none-any.whl (127 kB)\n",
      "Downloading more_itertools-10.6.0-py3-none-any.whl (63 kB)\n",
      "Downloading pbr-6.1.1-py2.py3-none-any.whl (108 kB)\n",
      "Downloading psycopg2_binary-2.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests_file-2.1.0-py2.py3-none-any.whl (4.2 kB)\n",
      "Downloading curies-0.10.10-py3-none-any.whl (56 kB)\n",
      "Downloading more_click-0.1.2-py3-none-any.whl (6.7 kB)\n",
      "Downloading multisplitby-0.0.1-py3-none-any.whl (4.0 kB)\n",
      "Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
      "Downloading PyTrie-0.4.0-py3-none-any.whl (6.1 kB)\n",
      "Downloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
      "Building wheels for collected packages: ratelimit\n",
      "  Building wheel for ratelimit (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ratelimit: filename=ratelimit-2.2.1-py3-none-any.whl size=5895 sha256=2f68e5da7668a74c8d532f5614a96e266fb88f683e45336e1d61a1edb98425d1\n",
      "  Stored in directory: /home/axelelia100/.cache/pip/wheels/ee/d5/e5/8fbffe089140fb498987b7709becf861086daace105d243475\n",
      "Successfully built ratelimit\n",
      "Installing collected packages: ratelimit, bottle, rdkit, pytrie, psycopg2-binary, prettytable, pbr, multisplitby, more-itertools, more_click, humanize, dnspython, colorlog, click-plugins, requests-file, pystow, pysmiles, email-validator, optuna, curies, bel-resources, bioregistry, pybel, jupyterlab-optuna\n",
      "Successfully installed bel-resources-0.0.3 bioregistry-0.12.7 bottle-0.13.2 click-plugins-1.1.1 colorlog-6.9.0 curies-0.10.10 dnspython-2.7.0 email-validator-2.2.0 humanize-4.12.1 jupyterlab-optuna-0.2.2 more-itertools-10.6.0 more_click-0.1.2 multisplitby-0.0.1 optuna-4.2.1 pbr-6.1.1 prettytable-3.15.1 psycopg2-binary-2.9.10 pybel-0.15.5 pysmiles-2.0.0 pystow-0.7.0 pytrie-0.4.0 ratelimit-2.2.1 rdkit-2024.9.6 requests-file-2.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install jupyterlab jupyterlab-optuna rdkit pysmiles prettytable pybel optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e392646-d124-4333-9414-a48f099bc24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from prettytable import PrettyTable\n",
    "import multiprocessing\n",
    "from scipy import stats\n",
    "import os, sys, gc\n",
    "import time\n",
    "import optuna\n",
    "import optuna.visualization as vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98b664da-77d3-485c-9bc5-9cdd8288179a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cores: 24, GPUs: 1\n",
      "Cuda available: True\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "file_dir = os.path.dirname(\"../\")\n",
    "sys.path.append(file_dir)\n",
    "\n",
    "from anima.smiles import SMILES\n",
    "\n",
    "sml = SMILES()\n",
    "\n",
    "cores = int(multiprocessing.cpu_count())\n",
    "print(f\"Cores: {cores}, GPUs: {torch.cuda.device_count()}\")\n",
    "\n",
    "# Checking CUDA\n",
    "torch.cuda.empty_cache()\n",
    "use_cuda = True\n",
    "print(f\"Cuda available: {torch.cuda.is_available()}\")\n",
    "device = torch.device(\n",
    "    \"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a3ce113-6852-4bb0-a25d-8d8e3e39d481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Database shape: (41801, 20)\n",
      "\n",
      "\n",
      "New size of train database: (41801, 21)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "database = pd.read_csv(\"../anima-master/databases/OMEAD_41801.csv\")\n",
    "\n",
    "print(f\"\\nDatabase shape: {database.shape}\\n\")\n",
    "\n",
    "train_db = database\n",
    "train_db[\"homo_lumo_gap\"] = train_db.lumo - train_db.homo\n",
    "smiles = np.array(train_db.smiles)\n",
    "#train_db.to_csv(\"changed_test200k.csv\")\n",
    "print(f\"\\nNew size of train database: {train_db.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea116aab-8c72-49d7-8eb5-7f0788410aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Defining SMILES vocabulary\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 152 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=24)]: Done 402 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=24)]: Done 752 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=24)]: Done 1202 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=24)]: Done 1752 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=24)]: Done 2402 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=24)]: Done 3152 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=24)]: Done 4002 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=24)]: Done 4952 tasks      | elapsed:   12.7s\n",
      "[Parallel(n_jobs=24)]: Done 6002 tasks      | elapsed:   16.4s\n",
      "[Parallel(n_jobs=24)]: Done 7152 tasks      | elapsed:   20.4s\n",
      "[Parallel(n_jobs=24)]: Done 8402 tasks      | elapsed:   24.6s\n",
      "[Parallel(n_jobs=24)]: Done 9752 tasks      | elapsed:   29.6s\n",
      "[Parallel(n_jobs=24)]: Done 11202 tasks      | elapsed:   34.8s\n",
      "[Parallel(n_jobs=24)]: Done 12752 tasks      | elapsed:   40.3s\n",
      "[Parallel(n_jobs=24)]: Done 14402 tasks      | elapsed:   46.3s\n",
      "[Parallel(n_jobs=24)]: Done 16152 tasks      | elapsed:   52.8s\n",
      "[Parallel(n_jobs=24)]: Done 18002 tasks      | elapsed:   59.3s\n",
      "[Parallel(n_jobs=24)]: Done 19952 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=24)]: Done 22002 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=24)]: Done 24152 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=24)]: Done 26402 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=24)]: Done 28752 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=24)]: Done 31202 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=24)]: Done 33752 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=24)]: Done 36402 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=24)]: Done 39152 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=24)]: Done 41801 out of 41801 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Size of vocabulary: 33\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define SMILES vocabulary\n",
    "\n",
    "print(\"\\nDefining SMILES vocabulary\\n\")\n",
    "vocab = sml.smilesVOC(smiles, n_jobs=cores)\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "print(f\"\\nSize of vocabulary: {vocab_size}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fdc4bbd-d75d-4391-a8a7-73ab54b35ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41801\n",
      "Check packing shape: torch.Size([41801, 224, 1])\n",
      "\n",
      "\n",
      "Max length of tensor sequences: 224\n",
      "\n",
      "Test size: (5017, 224)\n",
      "\n",
      "\n",
      "Train size: (36784, 224)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preparing SMILES into SEQUENCES or 1h tensors\n",
    "# for embeddings\n",
    "all_sequences = []\n",
    "\n",
    "l = 1\n",
    "for i in smiles:\n",
    "    print(l, end=\"\\r\")\n",
    "    all_sequences.append(torch.tensor(sml.smilesToSequence(i, vocab)))\n",
    "    l += 1\n",
    "\n",
    "# for embeddings\n",
    "packing = torch.nn.utils.rnn.pack_sequence(\n",
    "    all_sequences,\n",
    "    enforce_sorted = False\n",
    ")\n",
    "\n",
    "packing_padding = torch.nn.utils.rnn.pad_packed_sequence(\n",
    "    packing,\n",
    "    batch_first = True\n",
    ")\n",
    "\n",
    "# Check dimensions\n",
    "# for embedding\n",
    "# BATCH x SEQUENCE x INFO\n",
    "print(f\"\\nCheck packing shape: {packing_padding[0][:,:,:].size()}\\n\")\n",
    "\n",
    "temp = packing_padding[0][:,:,0]\n",
    "random_state = 1\n",
    "test_size = 0.12\n",
    "\n",
    "# inputs\n",
    "x_train, x_test = train_test_split(\n",
    "    temp.numpy(),\n",
    "    test_size=test_size,\n",
    "    random_state=1\n",
    ")\n",
    "del temp\n",
    "\n",
    "gap = np.array(train_db.homo_lumo_gap)\n",
    "# targets / outputs\n",
    "y_train, y_test = train_test_split(\n",
    "    gap,\n",
    "    test_size=test_size,\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "max_length = x_train.shape[-1]\n",
    "\n",
    "# max length of tensor sequences\n",
    "print(f\"\\nMax length of tensor sequences: {x_train.shape[-1]}\")\n",
    "\n",
    "print(f\"\\nTest size: {x_test.shape}\\n\")\n",
    "print(f\"\\nTrain size: {x_train.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a5f5e95-e982-48c4-bad8-ddf23fd818bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define TOOLS\n",
    "def model_evaluation(model, x_test, y_test, device):\n",
    "    batch_size=64\n",
    "\n",
    "    test_data = TensorDataset(\n",
    "        torch.tensor(x_test),\n",
    "        torch.tensor(y_test)\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_data,\n",
    "        shuffle= False,\n",
    "        batch_size= batch_size,\n",
    "        drop_last = False\n",
    "    )\n",
    "\n",
    "    running_mae = []\n",
    "    running_mse = []\n",
    "    mae = torch.nn.L1Loss().to(device)\n",
    "    mse = torch.nn.SmoothL1Loss().to(device)\n",
    "\n",
    "    model.eval().to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in enumerate(test_loader):\n",
    "            inputs, targets = data\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            targets = targets.double()\n",
    "\n",
    "            output = model(inputs)\n",
    "\n",
    "            loss_mae = mae(output, targets)\n",
    "            loss_mse = mse(output, targets)\n",
    "\n",
    "            running_mae.append(loss_mae.item())\n",
    "            running_mse.append(loss_mse.item())\n",
    "            \n",
    "    model.train()\n",
    "    return np.mean(running_mae), np.mean(running_mse)\n",
    "\n",
    "\n",
    "def model_predictions(model, x, device, batch_size = 64):\n",
    "    # predictions\n",
    "\n",
    "    model.eval().to(device)\n",
    "\n",
    "    pred_data = TensorDataset(torch.tensor(x))\n",
    "    pred_loader = DataLoader(\n",
    "        pred_data,\n",
    "        shuffle=False,\n",
    "        batch_size=batch_size,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    batches = len(x) / batch_size\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in enumerate(pred_loader):\n",
    "            print(f\"Batch: {batch_idx + 1:010.2f} of {batches:010.2f}\", end=\"\\r\")\n",
    "            inputs = data[0]\n",
    "            inputs = inputs.to(device)\n",
    "\n",
    "            output = model(inputs)\n",
    "            if batch_idx == 0:\n",
    "                temp = output.cpu().detach().numpy()\n",
    "            else:\n",
    "                temp = np.append(temp, output.cpu().detach().numpy())\n",
    "            del inputs, output\n",
    "\n",
    "    return np.reshape(temp, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99e04002-76af-4718-b64f-3363b3c26670",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SMILESTransformerRegressor(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, n_heads, n_layers, hidden_dim, max_len, output_dim, dropout):\n",
    "        super(SMILESTransformerRegressor, self).__init__()\n",
    "\n",
    "        self.embeddings = nn.Embedding(vocab_size + 1, embed_dim, padding_idx=0)\n",
    "\n",
    "        # Positional encoding\n",
    "        self.positional_encoding = nn.Parameter(torch.randn(1, max_len, embed_dim))\n",
    "\n",
    "\n",
    "        # Transformer encoding\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "                d_model=embed_dim,\n",
    "                nhead=n_heads,\n",
    "                dim_feedforward=hidden_dim,\n",
    "                dropout=dropout,\n",
    "                batch_first=True\n",
    "                )\n",
    "\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "                encoder_layer,\n",
    "                num_layers=n_layers)\n",
    "\n",
    "        # Regression head\n",
    "        self.fc = nn.Sequential(\n",
    "                nn.Linear(embed_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_dim, output_dim)\n",
    "                )\n",
    "\n",
    "    def forward(self, x):\n",
    "         \"\"\"\n",
    "         x: Tensor of shape (batch_size, seq_len)\n",
    "         \"\"\"\n",
    "         batch_size, seq_len = x.shape\n",
    "\n",
    "         # Embed and add positional encoding\n",
    "         x_embed = self.embeddings(x) # (batch size, seq_len, embed_dim)\n",
    "\n",
    "         # If sequence is shorter than max_len, crop pos encoding\n",
    "         pos_enc = self.positional_encoding[:, :seq_len, :].to(x.device) # (1, seq_len, embed_dim)\n",
    "         x_embed = x_embed + pos_enc\n",
    "\n",
    "         # Transformer expects input shape (batch_size, seq_len, embed_dim)\n",
    "         x_transformed = self.transformer_encoder(x_embed)\n",
    "\n",
    "         # Pooling: mean over sequence dimension\n",
    "         x_pooled = x_transformed.mean(dim=1) # (batch_size, embed_dim)\n",
    "\n",
    "         out = self.fc(x_pooled) # (batch_size, 1)\n",
    "         return out.squeeze(1) # (batch_size, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5c39bf2-c9b0-4f01-b608-e03306d9f206",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "\n",
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    try:\n",
    "        # Suggest hyperparameters\n",
    "        embed_dim = trial.suggest_categorical(\"embed_dim\", [64, 128, 256, 512])\n",
    "        n_heads = trial.suggest_categorical(\"n_heads\", [2, 4, 8])\n",
    "        n_layers = trial.suggest_int(\"n_layers\", 1, 6)\n",
    "        hidden_dim = trial.suggest_int(\"hidden_dim\", 128, 1024, log=True)\n",
    "        weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-2, log=True)\n",
    "        batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128, 256])\n",
    "        learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)\n",
    "        dropout = trial.suggest_float('dropout', 0.0, 0.5)\n",
    "\n",
    "    \n",
    "        # Optional: Check compatibility of embed_dim and n_heads\n",
    "        if embed_dim % n_heads != 0:\n",
    "            raise optuna.exceptions.TrialPruned()  # Invalid combo\n",
    "    \n",
    "        # Model Initialization\n",
    "        model = SMILESTransformerRegressor(\n",
    "            vocab_size,\n",
    "            embed_dim=embed_dim,\n",
    "            n_heads=n_heads,\n",
    "            n_layers=n_layers,\n",
    "            hidden_dim=hidden_dim,\n",
    "            max_len=max_length,\n",
    "            output_dim=1,\n",
    "            dropout=dropout\n",
    "        ).float().to(device)\n",
    "            \n",
    "    \n",
    "        # Loss and Optimizer\n",
    "        criterion = nn.SmoothL1Loss().double().to(device)\n",
    "        optimizer = torch.optim.Adam(\n",
    "            model.parameters(),\n",
    "            lr=learning_rate,\n",
    "            weight_decay=weight_decay)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=10)\n",
    "                                    \n",
    "    \n",
    "        # Data Loaders\n",
    "        train_data = TensorDataset(torch.tensor(x_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32))\n",
    "        train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, drop_last=False, pin_memory=True)\n",
    "\n",
    "        # Data loaders for validation\n",
    "        val_data = TensorDataset(torch.tensor(x_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32))\n",
    "        val_loader = DataLoader(val_data, shuffle=False, batch_size=batch_size, drop_last=False, pin_memory=True)\n",
    "    \n",
    "        # Training Loop (Reduced Epochs for Speed)\n",
    "        best_val_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "        epochs = 500  # Reduce for faster optimization\n",
    "        #accumulation_steps = 2\n",
    "        #model.train()\n",
    "    \n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            train_losses = []\n",
    "\n",
    "            for x_batch, y_batch in train_loader:\n",
    "                x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                output = model(x_batch)\n",
    "                loss = criterion(output, y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_losses.append(loss.item())\n",
    "            \n",
    "\n",
    "            # Evaluate on validation set\n",
    "            model.eval()\n",
    "            val_losses = []\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for x_val, y_val in val_loader:\n",
    "                    x_val, y_val = x_val.to(device), y_val.to(device)\n",
    "                    output = model(x_val)\n",
    "                    val_loss = criterion(output, y_val)\n",
    "                    val_losses.append(val_loss.item())\n",
    "\n",
    "            avg_train_loss = sum(train_losses) / len(train_losses)\n",
    "            avg_val_loss = sum(val_losses) / len(val_losses)\n",
    "            scheduler.step(avg_val_loss)\n",
    "\n",
    "            # Prune if it's bad\n",
    "            trial.report(avg_val_loss, epoch)\n",
    "            if trial.should_prune():\n",
    "                raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "            print(f\"Trial {trial.number} | Epoch {epoch} | Val Loss: {avg_val_loss:.5f} | Train Loss: {avg_train_loss:.5f}\")\n",
    "\n",
    "\n",
    "            # Early stopping manually (optional)\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= 30:  # patience limit\n",
    "                    break\n",
    "\n",
    "            # Track overfitting (optional)\n",
    "            overfit_gap = avg_val_loss - avg_train_loss\n",
    "            trial.set_user_attr(\"overfit_gap\", overfit_gap)\n",
    "\n",
    "        return best_val_loss  # this is what Optuna will minimize\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        if 'out of memory' in str(e):\n",
    "            print(\"CUDA OOM. Skipping this trial.\")\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "            return float('inf')\n",
    "        else:\n",
    "            raise\n",
    "    finally:\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721a3e78-8275-4d9f-be43-d731c07f3cb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-24 11:24:36,748] A new study created in memory with name: RNN Hyperparameter Optimization\n",
      "[W 2025-03-24 11:31:05,955] Trial 0 failed with parameters: {'embed_dim': 128, 'n_heads': 8, 'n_layers': 2, 'hidden_dim': 880, 'weight_decay': 0.0015423589604909055, 'batch_size': 256, 'learning_rate': 0.0012962594688829706, 'dropout': 0.09246618965108322} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-03-24 11:31:05,955] Trial 0 failed with value nan.\n",
      "[W 2025-03-24 11:46:07,397] Trial 1 failed with parameters: {'embed_dim': 64, 'n_heads': 8, 'n_layers': 5, 'hidden_dim': 867, 'weight_decay': 2.6980243151556872e-06, 'batch_size': 128, 'learning_rate': 0.00946910464098346, 'dropout': 0.4400440177505704} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-03-24 11:46:07,398] Trial 1 failed with value nan.\n",
      "[I 2025-03-24 11:54:20,068] Trial 2 finished with value: 0.029659311577345783 and parameters: {'embed_dim': 128, 'n_heads': 2, 'n_layers': 4, 'hidden_dim': 144, 'weight_decay': 0.001258752132773263, 'batch_size': 64, 'learning_rate': 5.762461435905236e-05, 'dropout': 0.21233210217741133}. Best is trial 2 with value: 0.029659311577345783.\n"
     ]
    }
   ],
   "source": [
    "# Create Optuna study and optimize the objective function\n",
    "study = optuna.create_study(direction='minimize', study_name='RNN Hyperparameter Optimization')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Output the best hyperparameters\n",
    "print('Best hyperparameters found:')\n",
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3fcf94-f9a5-4d50-8177-1e1774eebdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna.visualization as vis\n",
    "\n",
    "# Visualize parameter importance and optimization history\n",
    "vis.plot_param_importances(study).show()\n",
    "vis.plot_optimization_history(study).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0b4e66-25da-41a0-8631-06921db1f334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"best_param.json\", 'w') as f:\n",
    "    json.dump(study.best_params, f, indent=4)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53602cf6-db27-49d1-96f6-c0e670fb4279",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Script done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be55a720-24fc-4d0b-953b-b2cd1832d9ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
